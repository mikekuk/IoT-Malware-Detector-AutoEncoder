{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers, losses, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/happyemoji/botnet-detection-with-an-autoencoder#1.-N-BaIoT-Dataset\n",
    "\n",
    "Paper at: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8490192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nbaiot(filename):\n",
    "    return np.loadtxt(\n",
    "        os.path.join(\"./data\", filename),\n",
    "        delimiter=\",\",\n",
    "        skiprows=1\n",
    "    )\n",
    "\n",
    "benign = load_nbaiot(f\"{SET}.benign.csv\")\n",
    "X_train = benign[:40000]\n",
    "X_test0 = benign[40000:]\n",
    "X_test1 = load_nbaiot(f\"{SET}.mirai.scan.csv\")\n",
    "X_test2 = load_nbaiot(f\"{SET}.mirai.ack.csv\")\n",
    "X_test3 = load_nbaiot(f\"{SET}.mirai.syn.csv\")\n",
    "X_test4 = load_nbaiot(f\"{SET}.mirai.udp.csv\")\n",
    "X_test5 = load_nbaiot(f\"{SET}.mirai.udpplain.csv\")\n",
    "X_test6 = load_nbaiot(f\"{SET}.gafgyt.combo.csv\")\n",
    "X_test7 = load_nbaiot(f\"{SET}.gafgyt.scan.csv\")\n",
    "X_test8 = load_nbaiot(f\"{SET}.gafgyt.tcp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_nbaiot(filename):\n",
    "#     return np.loadtxt(\n",
    "#         os.path.join(\"./data\", filename),\n",
    "#         delimiter=\",\",\n",
    "#         skiprows=1\n",
    "#     )\n",
    "\n",
    "# Doorbell = load_nbaiot(\"1.benign.csv\")\n",
    "# X_train = Doorbell[:40000]\n",
    "# X_test0 = Doorbell[40000:]\n",
    "# X_test1 = load_nbaiot(f\"2.benign.csv\")\n",
    "# X_test2 = load_nbaiot(f\"3.benign.csv\")\n",
    "# X_test3 = load_nbaiot(f\"4.benign.csv\")\n",
    "# X_test4 = load_nbaiot(f\"5.benign.csv\")\n",
    "# X_test5 = load_nbaiot(f\"6.benign.csv\")\n",
    "# X_test6 = load_nbaiot(f\"7.benign.csv\")\n",
    "# X_test7 = load_nbaiot(f\"8.benign.csv\")\n",
    "# X_test8 = load_nbaiot(f\"9.benign.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 115) (135240, 115) (103621, 115) (91123, 115) (118128, 115) (217034, 115) (80808, 115)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
    "      X_test3.shape, X_test4.shape, X_test5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(115, activation=\"relu\"),\n",
    "            layers.Dense(86, activation=\"relu\"),\n",
    "            layers.Dense(36, activation=\"relu\"),\n",
    "            layers.Dense(24, activation=\"relu\"),\n",
    "            layers.Dense(4, activation=\"relu\")\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(24, activation=\"relu\"),\n",
    "            layers.Dense(36, activation=\"relu\"),\n",
    "            layers.Dense(86, activation=\"relu\"),\n",
    "            layers.Dense(115, activation=\"sigmoid\")\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "875/875 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 3.5639e-04\n",
      "Epoch 2/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0029 - val_loss: 7.0695e-04\n",
      "Epoch 3/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0027 - val_loss: 3.5472e-04\n",
      "Epoch 4/800\n",
      "875/875 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 3.1097e-04\n",
      "Epoch 5/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 3.3462e-04\n",
      "Epoch 6/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 3.3780e-04\n",
      "Epoch 7/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 2.9864e-04\n",
      "Epoch 8/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 2.8467e-04\n",
      "Epoch 9/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 2.6805e-04\n",
      "Epoch 10/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0014 - val_loss: 2.6564e-04\n",
      "Epoch 11/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0016 - val_loss: 2.7288e-04\n",
      "Epoch 12/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0014 - val_loss: 2.5326e-04\n",
      "Epoch 13/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0014 - val_loss: 2.8234e-04\n",
      "Epoch 14/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 2.9144e-04\n",
      "Epoch 15/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 3.1169e-04\n",
      "Epoch 16/800\n",
      "875/875 [==============================] - 1s 1ms/step - loss: 0.0016 - val_loss: 2.8119e-04\n",
      "Epoch 17/800\n",
      "875/875 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 2.7594e-04\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(X_train)\n",
    "\n",
    "ae = Autoencoder()\n",
    "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
    "monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-9,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "ae.fit(\n",
    "    x=x,\n",
    "    y=x,\n",
    "    epochs=800,\n",
    "    validation_split=0.3,\n",
    "    shuffle=True,\n",
    "    callbacks=[monitor]\n",
    ")\n",
    "\n",
    "training_loss = losses.mse(x, ae(x))\n",
    "threshold = np.mean(training_loss)+np.std(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, threshold=threshold, window_size=82):\n",
    "    x = scaler.transform(x)\n",
    "    predictions = losses.mse(x, ae(x)) > threshold\n",
    "    # Majority voting over `window_size` predictions\n",
    "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
    "                     for i in range(window_size, len(predictions)+1)])\n",
    "\n",
    "def print_stats(data, outcome):\n",
    "    print(f\"Shape of data: {data.shape}\")\n",
    "    print(f\"Detected anomalies: {np.mean(outcome)*100}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Shape of data: (135240, 115)\n",
      "Detected anomalies: 2.7560132880533295%\n",
      "\n",
      "1\n",
      "Shape of data: (103621, 115)\n",
      "Detected anomalies: 100.0%\n",
      "\n",
      "2\n",
      "Shape of data: (91123, 115)\n",
      "Detected anomalies: 100.0%\n",
      "\n",
      "3\n",
      "Shape of data: (118128, 115)\n",
      "Detected anomalies: 100.0%\n",
      "\n",
      "4\n",
      "Shape of data: (217034, 115)\n",
      "Detected anomalies: 100.0%\n",
      "\n",
      "5\n",
      "Shape of data: (80808, 115)\n",
      "Detected anomalies: 100.0%\n",
      "\n",
      "6\n",
      "Shape of data: (58152, 115)\n",
      "Detected anomalies: 100.0%\n",
      "\n",
      "7\n",
      "Shape of data: (27859, 115)\n",
      "Detected anomalies: 100.0%\n",
      "\n",
      "8\n",
      "Shape of data: (92581, 115)\n",
      "Detected anomalies: 100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8]\n",
    "\n",
    "for i, x in enumerate(test_data):\n",
    "    print(i)\n",
    "    outcome = predict(x)\n",
    "    print_stats(x, outcome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Lab-M-LO8dSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccf94b827d0db0a8cbf4a76d6e2f5ce958ac9f875ab80404c5102ce4d010481b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
